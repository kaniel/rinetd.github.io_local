<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>yolo on 时光小栈</title><link>/tags/yolo/</link><description>Recent content in yolo on 时光小栈</description><generator>Hugo -- gohugo.io</generator><language>zh-Hans</language><managingEditor>rinetd@163.com (rinetd)</managingEditor><webMaster>rinetd@163.com (rinetd)</webMaster><copyright>Copyright (c) 2017. All rights reserved. (版权所有) &lt;a href=&#39;http://www.miitbeian.gov.cn/&#39;&gt;鲁ICP备17074587号-1&lt;/a&gt;</copyright><lastBuildDate>Sat, 01 Aug 2020 14:25:24 +0800</lastBuildDate><atom:link href="/tags/yolo/feed.xml" rel="self" type="application/rss+xml"/><item><title>darknet源码剖析（四）do_nms_sort详解</title><link>/ai/yolo/yolov3-src-darknet-do_nms/</link><pubDate>Sat, 01 Aug 2020 14:25:24 +0800</pubDate><author>rinetd@163.com (rinetd)</author><guid>/ai/yolo/yolov3-src-darknet-do_nms/</guid><description>darknet源码剖析（四）do_nms_sort详解 //将图片数据进行缩放 image resize_data = resize_image(original_data, g_global_set.object_detect_net_set.this_net.w, g_global_set.object_detect_net_set.this_net.h); //获取开始时间 double this_time = get_time_point(); //开始预测 network_predict(g_global_set.object_detect_net_set.this_net, resize_data.data); //计算预测</description></item><item><title>yolov3 src yolo layer</title><link>/ai/yolo/yolov3-src-yolo-layer/</link><pubDate>Tue, 28 Jul 2020 15:27:19 +0800</pubDate><author>rinetd@163.com (rinetd)</author><guid>/ai/yolo/yolov3-src-yolo-layer/</guid><description>史上最详细的Yolov3边框预测分析 - 知乎 5分钟GET AI - YOLO 如何做到一眼识别 - 知乎 关于神经网络是如何做到预测的，这一期我们不做科学家，先做码</description></item><item><title>yolov3 keshihua</title><link>/ai/yolo/yolov3-keshihua/</link><pubDate>Sat, 25 Jul 2020 08:40:56 +0800</pubDate><author>rinetd@163.com (rinetd)</author><guid>/ai/yolo/yolov3-keshihua/</guid><description>darknet优化经验-AlexeyAB大神经验 - pprp - 博客园 8.用自己训练的权重作为预训练 有时候训练到一半突然终止了，这时候从头开始训练又很</description></item><item><title>计算Yolov3的anchors</title><link>/ai/yolo/yolo-anchors/</link><pubDate>Tue, 12 May 2020 15:06:24 +0800</pubDate><author>rinetd@163.com (rinetd)</author><guid>/ai/yolo/yolo-anchors/</guid><description># coding=utf-8 # k-means ++ for YOLOv3 anchors # 通过k-means ++ 算法获取YOLOv3需要的anchors的尺寸 import numpy as np # 定义Box类，描述bounding box的坐标</description></item><item><title>yolov3</title><link>/ai/yolo/yolov3/</link><pubDate>Sat, 22 Feb 2020 17:44:54 +0800</pubDate><author>rinetd@163.com (rinetd)</author><guid>/ai/yolo/yolov3/</guid><description>代码：TensorFlow2.0-Examples/4-Object_Detection/YOLOV3 既然代码贴出来了，大家又这么喜欢问，那</description></item><item><title>yolov3 test</title><link>/ai/yolo/yolov3-test/</link><pubDate>Sat, 14 Dec 2019 14:19:07 +0800</pubDate><author>rinetd@163.com (rinetd)</author><guid>/ai/yolo/yolov3-test/</guid><description>使用opencv 运行yolov3 测试 包含视频和图片的检测 使用opencv 运行yolov3 测试 包含视频和图片的检测 armstrong1972/Install-OpenCV4.1.1-on-RaspberryPi-4b:</description></item><item><title>【YOLO】详解：YOLO-darknet训练自己的数据</title><link>/ai/yolo/yolov3-train/</link><pubDate>Tue, 10 Dec 2019 16:40:00 +0800</pubDate><author>rinetd@163.com (rinetd)</author><guid>/ai/yolo/yolov3-train/</guid><description>【目标检测一】YOLOV3从训练、测试到批量保存测试结果_人工智能_gusui7202的博客-CSDN博客 目标检测：YOLOv3: 训练自己的</description></item><item><title>目标检测------锚框-------anchor box</title><link>/ai/yolo/yolo-anchorbox/</link><pubDate>Mon, 09 Dec 2019 19:01:55 +0800</pubDate><author>rinetd@163.com (rinetd)</author><guid>/ai/yolo/yolo-anchorbox/</guid><description>AnchorBox的一些理解 - mxdsdo09的博客 深度学习笔记（四）---YOLO目标检测 - 一一 yolov3 生成对应自己样本的 anchor box 尺寸的代码 - 简书 Anchor</description></item><item><title>yolo bounding box</title><link>/ai/yolo/yolo-bounding-box/</link><pubDate>Mon, 09 Dec 2019 18:45:41 +0800</pubDate><author>rinetd@163.com (rinetd)</author><guid>/ai/yolo/yolo-bounding-box/</guid><description>目标检测3: yolov3结构原理，boundingbox边框回归_网络_u010397980的博客-CSDN博客 边框回归(Bounding Box</description></item><item><title>yolo flask server</title><link>/ai/yolo/yolo-flask-server/</link><pubDate>Mon, 11 Nov 2019 10:57:24 +0800</pubDate><author>rinetd@163.com (rinetd)</author><guid>/ai/yolo/yolo-flask-server/</guid><description>Image object detection demo(YOLO,SSD,etc.) running as a Flask web server</description></item><item><title>yolo macos</title><link>/ai/yolo/yolo-macos/</link><pubDate>Mon, 11 Nov 2019 09:06:19 +0800</pubDate><author>rinetd@163.com (rinetd)</author><guid>/ai/yolo/yolo-macos/</guid><description>VOC 检测图像 ./darknet detector test cfg/voc.data cfg/yolov3.cfg weights/yolov3.weights data/dog.jpg</description></item><item><title>yolo pretrain convert</title><link>/ai/yolo/yolo-pretrain-convert/</link><pubDate>Mon, 11 Nov 2019 08:51:20 +0800</pubDate><author>rinetd@163.com (rinetd)</author><guid>/ai/yolo/yolo-pretrain-convert/</guid><description>1.voc数据集转换 数据集目录结构 └── VOCdevkit └── VOC2012 ├── Annotations │ ├── 20190615163323424.xml │ ├── .......还有很多xml ├── ImageSets │ └── Main #标签的训练和验证</description></item><item><title>ncnn上运行mobilenet</title><link>/math/yolo/ncnn-mobilenet/</link><pubDate>Thu, 10 Oct 2019 11:37:32 +0800</pubDate><author>rinetd@163.com (rinetd)</author><guid>/math/yolo/ncnn-mobilenet/</guid><description>在ncnn上把玩mobileNet 下载MobileNet的caffe模型和配置文件 可从https://github.com/shicai/M</description></item><item><title>cafe</title><link>/math/yolo/cafe/</link><pubDate>Mon, 07 Oct 2019 17:24:05 +0800</pubDate><author>rinetd@163.com (rinetd)</author><guid>/math/yolo/cafe/</guid><description>install 安装说明：http://caffe.berkeleyvision.org/installation.html conda A. 环境安装 ubuntu16.</description></item><item><title>yoloV3参数理解及注释</title><link>/math/yolo/yolo-cfg/</link><pubDate>Tue, 17 Sep 2019 18:59:18 +0800</pubDate><author>rinetd@163.com (rinetd)</author><guid>/math/yolo/yolo-cfg/</guid><description>#define SAMPLE_SVP_NNIE_YOLOV3_REPORT_BLOB_NUM 3 /*yolov3 report blob num 输入图像的通道数*/ #define SAMPLE_SVP_NNIE_YOLOV3_EACH_GRID_BIAS_NUM 6 /*yolov3 bias num of each grid */ num=9 每个grid cell预测几个box,和anchors的数量一致。当想要使用更多anc</description></item><item><title>ncnn</title><link>/math/yolo/ncnn/</link><pubDate>Thu, 15 Aug 2019 18:40:10 +0800</pubDate><author>rinetd@163.com (rinetd)</author><guid>/math/yolo/ncnn/</guid><description>git@github.com:Ewenwan/MVision.git https://github.com/hjchen2/paddle-mobile-benchmark.git NCNN简单入门及安装 - 简书 NCNN使用总结 - 简书 MobilenetV2 Caffe model 转换成NCNN model 并基于NCNN推理测试 - 简书 RK3399上Tengine平台搭建</description></item></channel></rss>